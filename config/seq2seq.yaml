General:
  name: seq2seq_addition
  output_dir: "./output"
  seed: 20
  epoch: 10
  trainer:
    # ここの引数ほとんど分からんまま使ってる
    gpus: 1
    accumulate_grad_batches: 1
    progress_bar_refresh_rate: 1
    fast_dev_run: False
    num_sanity_val_steps: 0
    resume_from_checkpoint: None

dataloader:
  train:
    batch_size: 512
    shuffle: True
    num_workers: 4
    drop_last: True
  valid:
    batch_size: 512
    shuffle: False
    num_workers: 4
    drop_last: True

model:
  params:
    num_layers: 4
    hidden_size: 128
    

optimizer:
  name: optim.AdamW
  params:
    lr: !!python/float 1e-0

loss: nn.BCEWithLogitsLoss
